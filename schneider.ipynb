{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n# Data Science SE\n\n---\n#### **Los objetivos de este notebook son:**\n\n✅ Task 1 → Predictive model\n\n✅ Task 2 → Presentation \n\n\n# 1. Introducción:\n\nLa UE aporta el 18% del total de las emisiones de gases que provocan el calentamiento global; sin embargo, está cada vez más decidida a tomar la delantera en la lucha contra el cambio climático. Por eso se ha fijado el objetivo de alcanzar las cero emisiones de carbono en 2050.\n\nPara ello, ha puesto en marcha una gran cantidad de recursos que le ayudarán a alcanzar este objetivo en los próximos años, y para ello necesitará su ayuda.\n\n\n# 2. Conjuntos de datos:\n\nEl dataset completo está formado por tres partes:\n- `Parte train:`\n    - Primera parte: 2 datasets en formato csv. Estos forman el 50% del dataset total.\n        - `train_1.csv`\n        - `train_2.csv`\n    \n    - Segunda parte: 3 datasets en formato json. Estos forman el 49% del dataset total.\n        - `train_3.json`\n        - `train_4.json`\n        - `train_5.json` \n    \n    - Tercerta parte: 1 dataset en formato pdf. Este forma el 1% del dataset total.\n\n- `Parte test`\n\n# Características de todos los datasets:\n\n- `countryName`: Country in which the facility is located\n- `EPRETRSectorCode`: Code of the sector in which the company specialises\n- `eptrSectorName`: Name of the sector in which it specialises\n- `EPRTRAnnexIMainActivityCode`: Code of the specialisation within the sector in which they operate\n- `EPRTRAnnexIMainActivityLabel`: Specialisation within the sector in which they operate\n- `FacilityInspireID:` Building identifier\n- `facilityName`: Name of the building in which the activity takes place\n- `City`: City in which the facility is located\n- `CITY ID`: ID to confirm location\n- `targetRelease`: Type of polluter to study\n- `pollutant`: Type of pollutant emitted (Target variable). In order to follow the same standard, you must encode this variables as follows:\n    - Nitrogen oxides (NOX): 0\n    - Carbon dioxide (CO2): 1\n    - Methane (CH4): 2\n- `DAY`: Day on which the report is made\n- `MONTH:` Reporting month\n- `reportingYear`: Reporting year\n- `CONTINENT`: Continent on which the company is located\n- `max_wind_speed`: Maximum wind speed\n- `avg_wind_speed`: Average wind speed\n- `min_wind_speed`: Minimum wind speed\n- `max_temp`: Maximum temperature\n- `avg_temp`: Average temperature\n- `min_temp`: Minimum temperature\n- `DAYS WITH FOG`: Total days of the month recorded in the area\n- `REPORTER NAME`: Reporter's name\n\n# 3. Leer los datasets y unirlos para formar uno:\n\nAl set tres tipos de datasets hemos de saber unirlos de forma adecuada. Para ello debemos tener en cuenta, las columnas que los conforman, si están mal escritas las columnas...\n\nHe tenido un problema con el dataset tipo `pdf` ya que lo he sabido descargar y leer pero juntarlo con las características adecuadas ha sido dificil. Como conforma el 1% del dataset total he optado por dejarlo apartado. No obstante expongo hasta donde he llegado:\n\n- 1. `PDF`: usamos tabula y la API de pdf para poder hacerlo","metadata":{}},{"cell_type":"code","source":"pip install tabula-py","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-21T19:43:42.554918Z","iopub.execute_input":"2022-05-21T19:43:42.555214Z","iopub.status.idle":"2022-05-21T19:43:53.371623Z","shell.execute_reply.started":"2022-05-21T19:43:42.555182Z","shell.execute_reply":"2022-05-21T19:43:53.370727Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"pip install git+https://github.com/pdftables/python-pdftables-api.git","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:31:38.781227Z","iopub.execute_input":"2022-05-21T17:31:38.781718Z","iopub.status.idle":"2022-05-21T17:31:52.954075Z","shell.execute_reply.started":"2022-05-21T17:31:38.781684Z","shell.execute_reply":"2022-05-21T17:31:52.953326Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cluster import KMeans\n\nfrom scipy import stats\nfrom scipy.stats import norm\n\nimport os\nimport gc\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as K\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import RobustScaler, LabelEncoder\nfrom sklearn.metrics import confusion_matrix\n\nfrom scipy.stats import zscore\nfrom scipy.stats import iqr\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\n# Import Module\nimport tabula\nimport pdftables_api\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# setting some globl config\nplt.style.use('fivethirtyeight')\ncust_color = ['#fdc029',\n'#f7c14c',\n'#f0c268',\n'#e8c381',\n'#dfc498',\n'#d4c5af',\n'#c6c6c6',\n'#a6a6a8',\n'#86868a',\n'#68686d',\n'#4b4c52',\n'#303138',\n'#171820',\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-21T20:59:20.974018Z","iopub.execute_input":"2022-05-21T20:59:20.975113Z","iopub.status.idle":"2022-05-21T20:59:20.991467Z","shell.execute_reply.started":"2022-05-21T20:59:20.975062Z","shell.execute_reply":"2022-05-21T20:59:20.990453Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"def eli_plot(df, feature, title):\n    \n    # Creating a customized chart. and giving in figsize and everything.\n    \n    fig = plt.figure(constrained_layout=True)\n    \n    # creating a grid of 3 cols and 3 rows.\n    \n    grid = gridspec.GridSpec(ncols=3, nrows=2, figure=fig)\n\n    # Customizing the histogram grid.\n    \n    ax1 = fig.add_subplot(grid[0, :2])\n    \n    # Set the title.\n    \n    ax1.set_title('Histogram')\n    \n    # plot the histogram.\n    \n    sns.distplot(df.loc[:, feature],\n                 hist=True,\n                 kde=True,\n                 fit=norm,\n                  hist_kws={\n                 'rwidth': 0.85,\n                 'edgecolor': 'black',\n                 'linewidth':.5,\n                 'alpha': 0.8},\n                 ax=ax1,\n                 color=cust_color[0])\n    \n    ax1.axvline(df.loc[:, feature].mean(), color='Green', linestyle='dashed', linewidth=3)\n\n    min_ylim, max_ylim = plt.ylim()\n    ax1.text(df.loc[:, feature].mean()*1.25, max_ylim*0.85, \n             'Mean: {:.2f}'.format(df.loc[:, feature].mean()), \n             color='Green', fontsize='12',\n             bbox=dict(boxstyle='round',facecolor='red', alpha=0.5))\n    ax1.legend(labels=['Actual','Normal'])\n    ax1.xaxis.set_major_locator(MaxNLocator(nbins=12))\n    \n    \n    ax1.annotate(\n    # Label and coordinate\n    'Unexpected Spike here!', xy=(10000, 0.00025),xytext=(10500, 0.0004) ,\n    horizontalalignment=\"center\",\n    # Custom arrow\n    arrowprops=dict(arrowstyle='simple',lw=1, color='black'), fontsize=8\n    )\n\n    # customizing the QQ_plot.\n    \n    ax2 = fig.add_subplot(grid[1, :2])\n    \n    # Set the title.\n    \n    ax2.set_title('Probability Plot')\n    \n    # Plotting the QQ_Plot.\n    stats.probplot(df.loc[:, feature],\n                   plot=ax2)\n    ax2.get_lines()[0].set_markerfacecolor('#e74c3c')\n    ax2.get_lines()[0].set_markersize(12.0)\n    ax2.xaxis.set_major_locator(MaxNLocator(nbins=16))\n\n    # Customizing the Box Plot:\n    \n    ax3 = fig.add_subplot(grid[:, 2])\n    # Set title.\n    \n    ax3.set_title('Box Plot')\n    \n    # Plotting the box plot.\n    \n    sns.boxplot(y=feature, data=df, ax=ax3, color=cust_color[0])\n    ax3.yaxis.set_major_locator(MaxNLocator(nbins=24))\n\n    plt.suptitle(f'{title}', fontsize=24, fontname = 'monospace', weight='bold')\n    \n    \ndef count_dist(df, colname=None, fixlabel=False, f_axis=None, fixlabel_n=None, fixlabel_txt=None, max_idx=30, fontsize=12, palette=cust_color, rotation=45,\n              title='X distribution', y_label='', shift=-0.005):\n    \"\"\"A function for counting and displaying categorical variables including percentage texts.\"\"\"\n    fig, ax = plt.subplots()\n    sns.barplot(y=df[colname].value_counts().index[:max_idx],\n                x=df[colname].value_counts().values[:max_idx], palette=palette, \n                edgecolor='black', linewidth=1.5, saturation = 1.5)\n    z=df[colname].value_counts().values[:max_idx]\n    for n, i in enumerate(df[colname].value_counts().index[:max_idx]):    \n        ax.text(df[colname].value_counts().values[:max_idx][n]+shift, \n                n, #Y location\n                s=f'{round(z[n]/df.shape[0]*100,1)}%',                 \n                va='center', \n                ha='right', \n                color='white', \n                fontsize=fontsize,\n                bbox=dict(boxstyle='round',facecolor='black', alpha=0.5))\n    if fixlabel:\n        if f_axis == 'x':\n            labels = [item.get_text() for item in ax.get_xticklabels()]\n            labels[fixlabel_n] = fixlabel_txt\n            ax.set_xticklabels(labels)\n        else:\n            labels = [item.get_text() for item in ax.get_yticklabels()]\n            labels[fixlabel_n] = fixlabel_txt\n            ax.set_yticklabels(labels)            \n\n    plt.title(title, fontname = 'monospace', weight='bold')\n    del z\n    \n    plt.yticks(fontsize=12,rotation=rotation)\n    plt.xlabel(\"Count\", fontname = 'monospace', weight='semibold')\n    plt.ylabel(y_label, fontname = 'monospace', weight='semibold')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:11:08.338297Z","iopub.execute_input":"2022-05-21T21:11:08.338583Z","iopub.status.idle":"2022-05-21T21:11:08.370355Z","shell.execute_reply.started":"2022-05-21T21:11:08.338554Z","shell.execute_reply":"2022-05-21T21:11:08.369544Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:31:55.832408Z","iopub.execute_input":"2022-05-21T17:31:55.832637Z","iopub.status.idle":"2022-05-21T17:31:55.865300Z","shell.execute_reply.started":"2022-05-21T17:31:55.832611Z","shell.execute_reply":"2022-05-21T17:31:55.863090Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# API KEY VERIFICATION\nconversion = pdftables_api.Client('frv7t0zf47zt')\n  \nurls_list = ['pdfs-1.pdf','pdfs81543.pdf']\nfor urls in urls_list:\n    conversion.csv('../input/documentos/train6/'+ str(urls), str(urls)+'.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:31:56.059894Z","iopub.execute_input":"2022-05-21T17:31:56.060209Z","iopub.status.idle":"2022-05-21T17:31:57.046606Z","shell.execute_reply.started":"2022-05-21T17:31:56.060168Z","shell.execute_reply":"2022-05-21T17:31:57.045652Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"- 2. `JSON`: Los datasets en formato Json son más fáciles ya que están incorporada en la librería pandas.","metadata":{}},{"cell_type":"code","source":"URL_3 = 'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/first'\nURL_4 = 'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/second'\nURL_5 = 'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/third'","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:31:57.048082Z","iopub.execute_input":"2022-05-21T17:31:57.048298Z","iopub.status.idle":"2022-05-21T17:31:57.052426Z","shell.execute_reply.started":"2022-05-21T17:31:57.048272Z","shell.execute_reply":"2022-05-21T17:31:57.051663Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_3 = pd.read_json(URL_3)\ndf_4 = pd.read_json(URL_4)\ndf_5 = pd.read_json(URL_5)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:31:57.055388Z","iopub.execute_input":"2022-05-21T17:31:57.055602Z","iopub.status.idle":"2022-05-21T17:32:02.667394Z","shell.execute_reply.started":"2022-05-21T17:31:57.055576Z","shell.execute_reply":"2022-05-21T17:32:02.666483Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"- 3. `CSV`: Para ello hemos descargado los datasets desde la web de Schneider.","metadata":{}},{"cell_type":"code","source":"df_1 = pd.read_csv('../input/csv-format/train1.csv')\ndf_2 = pd.read_csv('../input/csv-format/train2.csv',sep=\";\")\ntest = pd.read_csv('../input/csv-format/test_x.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:02.669177Z","iopub.execute_input":"2022-05-21T17:32:02.669493Z","iopub.status.idle":"2022-05-21T17:32:03.573542Z","shell.execute_reply.started":"2022-05-21T17:32:02.669448Z","shell.execute_reply":"2022-05-21T17:32:03.572570Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Ahora vamos a comprobar si hay diferencias entre las columnas de los diferentes datasets. Vemos que entre el `test`y el df_1 (`csv`) hay 3 columnas que no aparecen:\n{'EPRTRAnnexIMainActivityCode', 'EPRTRSectorCode', 'test_index'}\nEntre los datasets tipo `csv` y `json` hay dos columnas que no aparecen:\n{'EPRTRAnnexIMainActivityCode', 'EPRTRSectorCode'}\n\nPartiendo de esta base, vamos a unir todos los datasets. Los pasos son:\n- `Paso 1`: ver que columnas son diferentes entre los datasets (comentado anteriormente)","metadata":{}},{"cell_type":"code","source":"# Todas las columnas de estos 3 dataframe son iguales\nset(df_1.columns).difference(df_2.columns)\nset(df_2.columns).difference(df_1.columns)\nset(test.columns).difference(df_1.columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.575058Z","iopub.execute_input":"2022-05-21T17:32:03.575686Z","iopub.status.idle":"2022-05-21T17:32:03.587468Z","shell.execute_reply.started":"2022-05-21T17:32:03.575610Z","shell.execute_reply":"2022-05-21T17:32:03.586643Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"set(df_4.columns).difference(df_3.columns)\nset(df_5.columns).difference(df_3.columns)\nset(df_4.columns).difference(test.columns)\nset(df_5.columns).difference(test.columns)\nset(df_3.columns).difference(test.columns)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.589104Z","iopub.execute_input":"2022-05-21T17:32:03.589570Z","iopub.status.idle":"2022-05-21T17:32:03.600135Z","shell.execute_reply.started":"2022-05-21T17:32:03.589535Z","shell.execute_reply":"2022-05-21T17:32:03.599168Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 2`: Vamos a ver las columnas de los dataset tipo json.","metadata":{}},{"cell_type":"code","source":"df_3.columns = ['id', 'CITY ID', 'CONTINENT', 'City', 'DAY', 'DAY WITH FOGS',\n       'EPRTRAnnexIMainActivityCode', 'EPRTRAnnexIMainActivityLabel',\n       'EPRTRSectorCode', 'FacilityInspireID', 'MONTH', 'REPORTER NAME',\n       'avg_temp', 'avg_wind_speed', 'countryName', 'eprtrSectorName',\n       'facilityName', 'max_temp', 'max_wind_speed', 'min_temp',\n       'min_wind_speed', 'pollutant', 'reportingYear', 'targetRelease']\n\ndf_4.columns = ['id', 'CITY ID', 'CONTINENT', 'City', 'DAY', 'DAY WITH FOGS',\n       'EPRTRAnnexIMainActivityCode', 'EPRTRAnnexIMainActivityLabel',\n       'EPRTRSectorCode', 'FacilityInspireID', 'MONTH', 'REPORTER NAME',\n       'avg_temp', 'avg_wind_speed', 'countryName', 'eprtrSectorName',\n       'facilityName', 'max_temp', 'max_wind_speed', 'min_temp',\n       'min_wind_speed', 'pollutant', 'reportingYear', 'targetRelease']\n\ndf_5.columns = ['id', 'CITY ID', 'CONTINENT', 'City', 'DAY', 'DAY WITH FOGS',\n       'EPRTRAnnexIMainActivityCode', 'EPRTRAnnexIMainActivityLabel',\n       'EPRTRSectorCode', 'FacilityInspireID', 'MONTH', 'REPORTER NAME',\n       'avg_temp', 'avg_wind_speed', 'countryName', 'eprtrSectorName',\n       'facilityName', 'max_temp', 'max_wind_speed', 'min_temp',\n       'min_wind_speed', 'pollutant', 'reportingYear', 'targetRelease']","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.601625Z","iopub.execute_input":"2022-05-21T17:32:03.602400Z","iopub.status.idle":"2022-05-21T17:32:03.614943Z","shell.execute_reply.started":"2022-05-21T17:32:03.602351Z","shell.execute_reply":"2022-05-21T17:32:03.614026Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df_info_json = pd.DataFrame()\n\nnames = df_4.columns\ndtype  = ['int64', 'object','object','object','int64','int64','object','object','int64','object','int64',\n'object','float64','float64','object','object','object','float64','float64',\n'float64','float64','object','int64','object']\n\ndf_info_json['Names'] = names\ndf_info_json['Dtype'] = dtype\n\ndf_info_json.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.616434Z","iopub.execute_input":"2022-05-21T17:32:03.616883Z","iopub.status.idle":"2022-05-21T17:32:03.648589Z","shell.execute_reply.started":"2022-05-21T17:32:03.616851Z","shell.execute_reply":"2022-05-21T17:32:03.647677Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 3`: Vamos a comprobar el tamaño de todos los datasets","metadata":{}},{"cell_type":"code","source":"print(df_1.shape, df_2.shape, df_3.shape, df_4.shape, df_5.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.650014Z","iopub.execute_input":"2022-05-21T17:32:03.650392Z","iopub.status.idle":"2022-05-21T17:32:03.657977Z","shell.execute_reply.started":"2022-05-21T17:32:03.650344Z","shell.execute_reply":"2022-05-21T17:32:03.657173Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 4`: Vamos a unir los csv y los json por separado:","metadata":{}},{"cell_type":"code","source":"# Poner un dataframe debajo del otro:\ndf_csv = pd.concat([df_1,df_2],axis=0)\n\n# Poner un dataframe debajo del otro:\ndf_json = pd.concat([df_3,df_4,df_5],axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.659514Z","iopub.execute_input":"2022-05-21T17:32:03.660460Z","iopub.status.idle":"2022-05-21T17:32:03.721175Z","shell.execute_reply.started":"2022-05-21T17:32:03.660417Z","shell.execute_reply":"2022-05-21T17:32:03.720225Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"set(df_json.columns).difference(df_csv.columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.722400Z","iopub.execute_input":"2022-05-21T17:32:03.722650Z","iopub.status.idle":"2022-05-21T17:32:03.729600Z","shell.execute_reply.started":"2022-05-21T17:32:03.722612Z","shell.execute_reply":"2022-05-21T17:32:03.728567Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_json_copy = df_json.drop(['EPRTRAnnexIMainActivityCode', 'EPRTRSectorCode', 'id'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.731305Z","iopub.execute_input":"2022-05-21T17:32:03.731806Z","iopub.status.idle":"2022-05-21T17:32:03.788885Z","shell.execute_reply.started":"2022-05-21T17:32:03.731763Z","shell.execute_reply":"2022-05-21T17:32:03.787992Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 5`: Vamos a cambiar el orden de las columnas del dataset para poder combinar los dataset tipo json y tipo csv:","metadata":{}},{"cell_type":"code","source":"# cambiar orden de las columnas para coincidir con el dataframe df_json_copy\ndf_csv = df_csv[['CITY ID', 'CONTINENT', 'City', 'DAY', 'DAY WITH FOGS',\n       'EPRTRAnnexIMainActivityLabel', 'FacilityInspireID', 'MONTH',\n       'REPORTER NAME', 'avg_temp', 'avg_wind_speed', 'countryName',\n       'eprtrSectorName', 'facilityName', 'max_temp', 'max_wind_speed',\n       'min_temp', 'min_wind_speed', 'pollutant', 'reportingYear',\n       'targetRelease']]","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.799443Z","iopub.execute_input":"2022-05-21T17:32:03.800161Z","iopub.status.idle":"2022-05-21T17:32:03.834148Z","shell.execute_reply.started":"2022-05-21T17:32:03.800112Z","shell.execute_reply":"2022-05-21T17:32:03.833214Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 6`: Dataset final:","metadata":{}},{"cell_type":"code","source":"# Poner un dataframe debajo del otro:\ndf_final = pd.concat([df_csv,df_json_copy],axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.835402Z","iopub.execute_input":"2022-05-21T17:32:03.835641Z","iopub.status.idle":"2022-05-21T17:32:03.891048Z","shell.execute_reply.started":"2022-05-21T17:32:03.835611Z","shell.execute_reply":"2022-05-21T17:32:03.890136Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Información general del dataset: \n\nVemos que está formado por 65628 entradas y 21 columnas. De las 21 columnas, 11 son de tipo `objeto`. Esto deberemos tenerlo en cuenta para el análisis.","metadata":{}},{"cell_type":"code","source":"df_final.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:03.892060Z","iopub.execute_input":"2022-05-21T17:32:03.892785Z","iopub.status.idle":"2022-05-21T17:32:04.015341Z","shell.execute_reply.started":"2022-05-21T17:32:03.892737Z","shell.execute_reply":"2022-05-21T17:32:04.014447Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 ¿Hay datos nulos?\n\nComo podemos comprobar no hay datos nulos.","metadata":{}},{"cell_type":"code","source":"df_final.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:04.017191Z","iopub.execute_input":"2022-05-21T17:32:04.017744Z","iopub.status.idle":"2022-05-21T17:32:04.125009Z","shell.execute_reply.started":"2022-05-21T17:32:04.017696Z","shell.execute_reply":"2022-05-21T17:32:04.123909Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 ¿Hay datos duplicados?\n\nSí hay la presencia de datos duplicados. En concreto el 11.5% de los datos son duplicados. Esto lo podemos ver en la gráfica y la tabla. Posteriormente, borraré estos datos. ","metadata":{}},{"cell_type":"code","source":"duplicated = pd.DataFrame()\nnames = ['duplicated values','good dataset']\nvalues = [11.5,88.5]\nduplicated['Names'] = names\nduplicated['Values %'] = values\nduplicated = duplicated.set_index('Names')\nduplicated","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:06.238036Z","iopub.execute_input":"2022-05-21T17:32:06.238560Z","iopub.status.idle":"2022-05-21T17:32:06.250806Z","shell.execute_reply.started":"2022-05-21T17:32:06.238528Z","shell.execute_reply":"2022-05-21T17:32:06.250236Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"labels = ['duplicated values','good dataset']\nvalues = [df_final[df_final.duplicated()==True].shape[0],df_final.shape[0]]\ncolors = ['green','lightgreen','gold', 'mediumturquoise', 'darkorange', 'lightgreen']\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\nfig.update_layout(margin = dict(t=0, l=0, r=0, b=0))\nfig.update_traces(marker=dict(colors=colors))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:08.050630Z","iopub.execute_input":"2022-05-21T17:32:08.050924Z","iopub.status.idle":"2022-05-21T17:32:08.359382Z","shell.execute_reply.started":"2022-05-21T17:32:08.050890Z","shell.execute_reply":"2022-05-21T17:32:08.358568Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_final = df_final.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:10.019713Z","iopub.execute_input":"2022-05-21T17:32:10.020033Z","iopub.status.idle":"2022-05-21T17:32:10.242271Z","shell.execute_reply.started":"2022-05-21T17:32:10.019998Z","shell.execute_reply":"2022-05-21T17:32:10.241573Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## 3.5 Reescritura de las columnas: \n\nVamos a reescribir las columnas para que todas tengan un formato parecido.","metadata":{}},{"cell_type":"code","source":"df_final.columns = ['City Id', 'Continent', 'City', 'Day', 'Day of fogs',\n       'EPRTRAnnexIMainActivityLabel', 'FacilityInspireID', 'Month',\n       'Reporter name', 'Avg_temp', 'Avg_wind_speed', 'CountryName',\n       'EprtrSectorName', 'FacilityName', 'Max_temp', 'Max_wind_speed',\n       'Min_temp', 'Min_wind_speed', 'Pollutant', 'Year',\n       'TargetRelease']","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:11.744129Z","iopub.execute_input":"2022-05-21T17:32:11.744445Z","iopub.status.idle":"2022-05-21T17:32:11.750200Z","shell.execute_reply.started":"2022-05-21T17:32:11.744412Z","shell.execute_reply":"2022-05-21T17:32:11.749335Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# 4. EDA\n\n## 4.1 Análisis univariable:\n\nVamos a ver las características de cada variable. En el momento de analizarla, vamos a ver si son significativas para el dataset o no.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.1. City Id\n\nSi vemos los datos a continuación, se observa que no es un valor Id como tal, ya que hay datos que se repiten y por otra parte hay demasiados datos poco representados. El mayor representa el 3% del dataset. Por estos motivos, hemos decidido borrarlo del dataset.","metadata":{}},{"cell_type":"code","source":"df_final['City Id'].value_counts(normalize=True)*100","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:14.057575Z","iopub.execute_input":"2022-05-21T17:32:14.057878Z","iopub.status.idle":"2022-05-21T17:32:14.081705Z","shell.execute_reply.started":"2022-05-21T17:32:14.057843Z","shell.execute_reply":"2022-05-21T17:32:14.080768Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Hay demasiados valores con poco peso en las variables, por lo tanto eliminamos esta columna","metadata":{}},{"cell_type":"code","source":"df_final = df_final.drop(['City Id'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:15.653299Z","iopub.execute_input":"2022-05-21T17:32:15.653589Z","iopub.status.idle":"2022-05-21T17:32:15.677657Z","shell.execute_reply.started":"2022-05-21T17:32:15.653559Z","shell.execute_reply":"2022-05-21T17:32:15.676536Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.2. Continent\n\nTodo la columna indica que el dataset es de Europa. Es lógico, ya que la investigación es de Europa. Por tanto, debido que no aporta mayor información, la eliminaremos.","metadata":{}},{"cell_type":"code","source":"df_final['Continent'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:16.951156Z","iopub.execute_input":"2022-05-21T17:32:16.951462Z","iopub.status.idle":"2022-05-21T17:32:16.965806Z","shell.execute_reply.started":"2022-05-21T17:32:16.951429Z","shell.execute_reply":"2022-05-21T17:32:16.965064Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"df_final = df_final.drop(['Continent'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:18.189275Z","iopub.execute_input":"2022-05-21T17:32:18.189539Z","iopub.status.idle":"2022-05-21T17:32:18.211595Z","shell.execute_reply.started":"2022-05-21T17:32:18.189511Z","shell.execute_reply":"2022-05-21T17:32:18.210900Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.3. City\n\nAquí miraremos las ciudades que han participado en este estudio. Comprobaremos que hay más de 1500 datos que no expone la ciudad. Para tener una mayor comprensión de estos datos, hemos mirado el `CountryName` y hemos visto que es de `United Kingdom`. Por tanto, hemos reemplazado los datos `--` a `Other_UK`.","metadata":{}},{"cell_type":"code","source":"df_final[df_final['City']=='--']['CountryName'].unique() # United Kingdom\n# reemplazamos por London","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:19.439645Z","iopub.execute_input":"2022-05-21T17:32:19.439929Z","iopub.status.idle":"2022-05-21T17:32:19.459126Z","shell.execute_reply.started":"2022-05-21T17:32:19.439900Z","shell.execute_reply":"2022-05-21T17:32:19.458172Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df_final.City.replace('--','Other_UK', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:20.067561Z","iopub.execute_input":"2022-05-21T17:32:20.068031Z","iopub.status.idle":"2022-05-21T17:32:20.079425Z","shell.execute_reply.started":"2022-05-21T17:32:20.067984Z","shell.execute_reply":"2022-05-21T17:32:20.078696Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"A continuación veremos un gráfico de las ciudades que más representan este dataset. La ciudad que más destaca es `Other_UK` seguidamente de `Antwerpen` y `Duisburg`.","metadata":{}},{"cell_type":"code","source":"count_dist(df=df_final, colname='City', \n           max_idx=12, fontsize=16, rotation=0,\n           title='City Distribution\\n',\n           shift=400, y_label = 'City')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:04:04.211569Z","iopub.execute_input":"2022-05-21T18:04:04.211882Z","iopub.status.idle":"2022-05-21T18:04:06.209823Z","shell.execute_reply.started":"2022-05-21T18:04:04.211846Z","shell.execute_reply":"2022-05-21T18:04:06.209019Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.4 Day\n\nVemos que se recopila datos desdel 1-28 de cada més incluidos. Esto debe ser debido al mes de Febrero. ","metadata":{}},{"cell_type":"code","source":"df_final['Day'].sort_values().unique() # hay hasta 28 días","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:22.321904Z","iopub.execute_input":"2022-05-21T17:32:22.322341Z","iopub.status.idle":"2022-05-21T17:32:22.334268Z","shell.execute_reply.started":"2022-05-21T17:32:22.322298Z","shell.execute_reply":"2022-05-21T17:32:22.333445Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Si vemos la gráfica a continuación sobre su distribución, vemos en qq-plot que no siguen una distribución normal. La media de los datos está en el día 14.","metadata":{}},{"cell_type":"code","source":"eli_plot(df_final, 'Day', 'Day Distribution\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:03:21.726353Z","iopub.execute_input":"2022-05-21T18:03:21.726643Z","iopub.status.idle":"2022-05-21T18:03:25.816419Z","shell.execute_reply.started":"2022-05-21T18:03:21.726611Z","shell.execute_reply":"2022-05-21T18:03:25.815446Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.5. Day of fogs\n\nLos días de viento como máximo representan 19 días de 28. Pero normalmente, la mediana indica 1 día.","metadata":{}},{"cell_type":"code","source":"df_final['Day of fogs'].sort_values().unique() # hasta 19 días con viento","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:23.837158Z","iopub.execute_input":"2022-05-21T17:32:23.837609Z","iopub.status.idle":"2022-05-21T17:32:23.847193Z","shell.execute_reply.started":"2022-05-21T17:32:23.837564Z","shell.execute_reply":"2022-05-21T17:32:23.846353Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"eli_plot(df_final, 'Day of fogs', 'Day of fogs Distribution\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:02:52.848858Z","iopub.execute_input":"2022-05-21T18:02:52.849344Z","iopub.status.idle":"2022-05-21T18:02:56.940819Z","shell.execute_reply.started":"2022-05-21T18:02:52.849296Z","shell.execute_reply":"2022-05-21T18:02:56.939981Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"###  4.1.6. EPRTRAnnexIMainActivityLabel\n\n\nIndica la actividad de la producción de polución. Vemos que las 3 más destacadas son:\n- Thermal power stations and other combustion installations.\n- Landfills (excluding landfills of inert waste and landfills, which were definitely closed before 16.7.2001 or for which the after-care phase required by the competent authorities according to Article 13 of Council Directive 1999/31/EC of 26 April 1999 on the landfill of waste has expired)\n- Installations for the incineration of non-hazardous waste in the scope of Directive 2000/76/EC of the European Parliament and of the Council of 4 December 2000 on the incineration of waste","metadata":{}},{"cell_type":"code","source":"count_dist(df=df_final, colname='EPRTRAnnexIMainActivityLabel', \n           max_idx=12, fontsize=16, rotation=0,\n           title='Activity label Distribution\\n',\n           shift=400, y_label = 'Activity label')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:02:08.702577Z","iopub.execute_input":"2022-05-21T18:02:08.703558Z","iopub.status.idle":"2022-05-21T18:02:12.514090Z","shell.execute_reply.started":"2022-05-21T18:02:08.703501Z","shell.execute_reply":"2022-05-21T18:02:12.513179Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.7. FacilityInspireID\n\nEn esta característica, vemos una serie de número sobre la identificación del edificio donde se hace el estudio. Como hay poco peso en la representabilidad de los datos, dicidimos eliminarlo.","metadata":{}},{"cell_type":"code","source":"df_final.FacilityInspireID.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:29.404112Z","iopub.execute_input":"2022-05-21T17:32:29.404403Z","iopub.status.idle":"2022-05-21T17:32:29.430103Z","shell.execute_reply.started":"2022-05-21T17:32:29.404367Z","shell.execute_reply":"2022-05-21T17:32:29.429048Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df_final = df_final.drop(['FacilityInspireID'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:32:31.046430Z","iopub.execute_input":"2022-05-21T17:32:31.047310Z","iopub.status.idle":"2022-05-21T17:32:31.069334Z","shell.execute_reply.started":"2022-05-21T17:32:31.047263Z","shell.execute_reply":"2022-05-21T17:32:31.068494Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.8. Reporter name\n\nAquí vemos una lista del nombre de los reporter. Hemos querido jugar un poco con la variable y ver en qué paises se han centrado más. Los 5 reporters más importantes son: ","metadata":{}},{"cell_type":"code","source":"df_report_names = pd.DataFrame()\nreport_names = ['Michael Brown','James Smith','Michael Smith','Michael Williams','Robert Jones']\nvalue_reports = [25,25,23,22,22]\ndf_report_names['Report names'] = report_names\ndf_report_names['Count'] = value_reports\ndf_report_names","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:33:39.598789Z","iopub.execute_input":"2022-05-21T17:33:39.599507Z","iopub.status.idle":"2022-05-21T17:33:39.616954Z","shell.execute_reply.started":"2022-05-21T17:33:39.599458Z","shell.execute_reply":"2022-05-21T17:33:39.616206Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Podemos ver que:\n- Michael Brown se centra en `España`.\n- James Smith se centra en `Polonia`.\n- Michael Smith se centra en `Italia`\n- Michael Williams se centra en `España`.\n- Robert Jones se centra en `UK` .\n\nHemos decidido borrar esta característica ya que no aporta información útil al conjunto del dataset.","metadata":{}},{"cell_type":"code","source":"df_mb = df_final[df_final['Reporter name']=='Michael Brown']\ndf_js = df_final[df_final['Reporter name']=='James Smith']\ndf_ms = df_final[df_final['Reporter name']=='Michael Smith']\ndf_mw = df_final[df_final['Reporter name']=='Michael Williams']\ndf_rj = df_final[df_final['Reporter name']=='Robert Jones']\ndf_report_info = pd.concat([df_mb,df_js,df_ms,df_mw,df_rj],axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:35:53.330081Z","iopub.execute_input":"2022-05-21T17:35:53.330352Z","iopub.status.idle":"2022-05-21T17:35:53.401544Z","shell.execute_reply.started":"2022-05-21T17:35:53.330323Z","shell.execute_reply":"2022-05-21T17:35:53.400636Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"fig = px.sunburst(data_frame=df_report_info,\n                  path=['Reporter name', 'CountryName'],\n                  color='CountryName',\n                  color_discrete_sequence=cust_color[::-4],\n                  title='Top Reporter Names vs Country '\n                 )\n\nfig.update_traces(textinfo='label')\nfig.update_layout(margin=dict(t=40, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:36:21.030045Z","iopub.execute_input":"2022-05-21T17:36:21.030321Z","iopub.status.idle":"2022-05-21T17:36:21.126562Z","shell.execute_reply.started":"2022-05-21T17:36:21.030293Z","shell.execute_reply":"2022-05-21T17:36:21.125632Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"df_final = df_final.drop(['Reporter name'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:36:31.806498Z","iopub.execute_input":"2022-05-21T17:36:31.807107Z","iopub.status.idle":"2022-05-21T17:36:31.826760Z","shell.execute_reply.started":"2022-05-21T17:36:31.807040Z","shell.execute_reply":"2022-05-21T17:36:31.825897Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.9. Average temperature\n\nA continuación veremos la distribució de esta variable. Se puede observar que no sigue una distribución normal y que la mediana está a 11 grados.","metadata":{}},{"cell_type":"code","source":"eli_plot(df_final, 'Avg_temp', 'Average Temperature Distribution\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:41:57.693721Z","iopub.execute_input":"2022-05-21T17:41:57.694563Z","iopub.status.idle":"2022-05-21T17:42:01.778893Z","shell.execute_reply.started":"2022-05-21T17:41:57.694521Z","shell.execute_reply":"2022-05-21T17:42:01.778275Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.10. Average wind speed\n\nVemos a continuación, que la característica no sigue una distribución normal y que la media está en 18.01 unidades de viento.","metadata":{}},{"cell_type":"code","source":"eli_plot(df_final, 'Avg_wind_speed', 'Average wind speed Distribution\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:43:22.500557Z","iopub.execute_input":"2022-05-21T17:43:22.500865Z","iopub.status.idle":"2022-05-21T17:43:26.610736Z","shell.execute_reply.started":"2022-05-21T17:43:22.500832Z","shell.execute_reply":"2022-05-21T17:43:26.610149Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.11. CountryName\n\nA los tres paises que se le han realizado más estudios son: UK, Germany y France.","metadata":{}},{"cell_type":"code","source":"df_final.CountryName.value_counts() \nfig, ax = plt.subplots(1, 2, figsize=(12,8))\nsns.barplot(x=df_final.CountryName.value_counts()[:12].index, \n            y=df_final.CountryName.value_counts()[:12].values, \n            palette=cust_color, ax=ax[0],\n           edgecolor='black', linewidth=1.5, saturation=1.5)\nax[0].yaxis.set_major_locator(MaxNLocator(nbins=20))\nax[0].tick_params(axis='x', which='major', labelsize=10, rotation=90)\nax[0].set_ylabel('Count', weight='semibold', fontname = 'monospace', rotation=90)\nax[0].set_xlabel('Country Group', weight='semibold', fontname = 'monospace')\n\nax[1].pie(df_final.CountryName.value_counts()[:12], \n          labels = df_final.CountryName.value_counts()[:12].index, \n          colors = cust_color, autopct='%1.1f%%',\n        explode=[0.03 for i in df_final.CountryName.value_counts()[:12].index])\n\n\nplt.suptitle('Country Distribution', fontname = 'monospace', weight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:52:18.056628Z","iopub.execute_input":"2022-05-21T17:52:18.056939Z","iopub.status.idle":"2022-05-21T17:52:19.353183Z","shell.execute_reply.started":"2022-05-21T17:52:18.056905Z","shell.execute_reply":"2022-05-21T17:52:19.352365Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.12.Sector in which it specialises\n\nHay 9 tipos de sectores. La más representada es `Energy Sector` seguida de `Waste and wastewater management`","metadata":{}},{"cell_type":"code","source":"count_dist(df=df_final, colname='EprtrSectorName', \n           max_idx=12, fontsize=16, rotation=0,\n           title='Sector Name Distribution\\n',\n           shift=400, y_label = 'Sector Name')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:00:43.052895Z","iopub.execute_input":"2022-05-21T18:00:43.053184Z","iopub.status.idle":"2022-05-21T18:00:45.118727Z","shell.execute_reply.started":"2022-05-21T18:00:43.053155Z","shell.execute_reply":"2022-05-21T18:00:45.118068Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.13.Facility Name\n\nEsta característica representa el lugar donde se han realizado los estudios. Es una característica poco significativa ya que la que representa mayor peso es `Enel Produzione S.p.A` con un 0.35% del dataset total.","metadata":{}},{"cell_type":"code","source":"(df_final.FacilityName.value_counts(normalize=True)*100)[:9]\n# es una variable poco significativa debido a que hay muchos valores unitarios y el mayor\n# presenta una cuota del 0.35 % del total.","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:45:38.926691Z","iopub.execute_input":"2022-05-21T17:45:38.927367Z","iopub.status.idle":"2022-05-21T17:45:38.956777Z","shell.execute_reply.started":"2022-05-21T17:45:38.927319Z","shell.execute_reply":"2022-05-21T17:45:38.955825Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"df_final = df_final.drop(['FacilityName'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:46:10.542112Z","iopub.execute_input":"2022-05-21T17:46:10.542568Z","iopub.status.idle":"2022-05-21T17:46:10.555936Z","shell.execute_reply.started":"2022-05-21T17:46:10.542517Z","shell.execute_reply":"2022-05-21T17:46:10.555141Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.14. Max temperature\n\nRepresenta la máxima temperatura de todo el dataset. Vemos que se aproxima a una distribución Gaussiana. ","metadata":{}},{"cell_type":"code","source":"eli_plot(df_final, 'Max_temp', 'Max temperature Distribution\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:47:03.005466Z","iopub.execute_input":"2022-05-21T17:47:03.005929Z","iopub.status.idle":"2022-05-21T17:47:07.099384Z","shell.execute_reply.started":"2022-05-21T17:47:03.005882Z","shell.execute_reply":"2022-05-21T17:47:07.098371Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.15. Max wind speed\n\nRepresenta la velocidad máxima del viento. Su distribución sí recuerda a una distribución normal con una media de 15.52 unidades de viento.","metadata":{}},{"cell_type":"code","source":"eli_plot(df_final, 'Max_wind_speed', 'Max wind speed Distribution\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:47:54.377826Z","iopub.execute_input":"2022-05-21T17:47:54.378114Z","iopub.status.idle":"2022-05-21T17:47:59.040427Z","shell.execute_reply.started":"2022-05-21T17:47:54.378085Z","shell.execute_reply":"2022-05-21T17:47:59.036780Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.16. Min temperature\n\nRepresenta la distribución de la temperatura mínima del dataset. Vemos que recuerda a una distribución normal con una media de 13.45 grados.","metadata":{}},{"cell_type":"code","source":"eli_plot(df_final, 'Min_temp', 'Min temperature Distribution\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:49:23.178020Z","iopub.execute_input":"2022-05-21T17:49:23.178369Z","iopub.status.idle":"2022-05-21T17:49:27.571185Z","shell.execute_reply.started":"2022-05-21T17:49:23.178340Z","shell.execute_reply":"2022-05-21T17:49:27.570074Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.17. Min wind speed\n\nRepresenta la distribución de la velocidad mínima de viento. Recuerda a una distribución Gaussiana con una media de 22.52 unidades de viento.","metadata":{}},{"cell_type":"code","source":"eli_plot(df_final, 'Min_wind_speed', 'Min wind speed Distribution\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:50:09.530168Z","iopub.execute_input":"2022-05-21T17:50:09.530878Z","iopub.status.idle":"2022-05-21T17:50:13.732200Z","shell.execute_reply.started":"2022-05-21T17:50:09.530836Z","shell.execute_reply":"2022-05-21T17:50:13.731107Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.18. Pollutant\n\nEsta característica es el target del dataset. Está formada por tres variables, por lo que es una variable categórica. El dataset no se puede considerar desbalanceado ya que todas las categorías están adecuadamente representadas.","metadata":{}},{"cell_type":"code","source":"df_final.Pollutant.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:50:24.519297Z","iopub.execute_input":"2022-05-21T17:50:24.519603Z","iopub.status.idle":"2022-05-21T17:50:24.541014Z","shell.execute_reply.started":"2022-05-21T17:50:24.519562Z","shell.execute_reply":"2022-05-21T17:50:24.540178Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# plotting and styling\nfig, ax = plt.subplots(figsize=(12,4))\nsns.barplot(x=df_final_copy['Pollutant'].value_counts().index,\n            y=df_final_copy['Pollutant'].value_counts().values,\n            palette=cust_color[::4],\n            edgecolor='black', linewidth=1.5, saturation=1.5)\nplt.xlabel(\"Type of Pollutant\", fontname = 'monospace', weight='semibold')\nplt.ylabel(\"Count\", fontname = 'monospace', weight='semibold')\nplt.title('Pollutant Distribution', fontname = 'monospace', weight='bold');","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:54:57.841317Z","iopub.execute_input":"2022-05-21T17:54:57.841582Z","iopub.status.idle":"2022-05-21T17:54:58.301637Z","shell.execute_reply.started":"2022-05-21T17:54:57.841554Z","shell.execute_reply":"2022-05-21T17:54:58.300739Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.19. Reporting Year\n\nEste es el año que se hizo el estudio. Los años son desde el 2008 - 2020 incluidos ambos. No obstante, vemos que hay más representación en los años iniciales que en los finales.","metadata":{}},{"cell_type":"code","source":"df_final.Year.value_counts() \nfig, ax = plt.subplots(1, 2, figsize=(12,8))\nsns.barplot(x=df_final.Year.value_counts()[:12].index, \n            y=df_final.Year.value_counts()[:12].values, \n            palette=cust_color, ax=ax[0],\n           edgecolor='black', linewidth=1.5, saturation=1.5)\nax[0].yaxis.set_major_locator(MaxNLocator(nbins=20))\nax[0].tick_params(axis='x', which='major', labelsize=10, rotation=90)\nax[0].set_ylabel('Count', weight='semibold', fontname = 'monospace', rotation=90)\nax[0].set_xlabel('Year Group', weight='semibold', fontname = 'monospace')\n\nax[1].pie(df_final.Year.value_counts()[:12], \n          labels = df_final.Year.value_counts()[:12].index, \n          colors = cust_color, autopct='%1.1f%%',\n        explode=[0.03 for i in df_final.Year.value_counts()[:12].index])\n\n\nplt.suptitle('Year Distribution', fontname = 'monospace', weight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:07:13.424223Z","iopub.execute_input":"2022-05-21T18:07:13.424625Z","iopub.status.idle":"2022-05-21T18:07:14.528782Z","shell.execute_reply.started":"2022-05-21T18:07:13.424596Z","shell.execute_reply":"2022-05-21T18:07:14.527936Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.20.Target Release\n\nEsta columna solo tiene un elemento `Air` por lo que decidimos eliminarla ya que no aporta información adicional al dataset.","metadata":{}},{"cell_type":"code","source":"df_final.TargetRelease.value_counts()\n# como esta columna solo tiene un valor 'AIR' lo podemos eliminar","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:50:56.264797Z","iopub.execute_input":"2022-05-21T17:50:56.265069Z","iopub.status.idle":"2022-05-21T17:50:56.283885Z","shell.execute_reply.started":"2022-05-21T17:50:56.265039Z","shell.execute_reply":"2022-05-21T17:50:56.282990Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"df_final = df_final.drop(['TargetRelease'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:51:00.944129Z","iopub.execute_input":"2022-05-21T17:51:00.944470Z","iopub.status.idle":"2022-05-21T17:51:00.965348Z","shell.execute_reply.started":"2022-05-21T17:51:00.944430Z","shell.execute_reply":"2022-05-21T17:51:00.964468Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Dataset Final\n\nEl dataset final consta de todo lo que hemos mencionado y a continuación añadiremos una gráfica de tiempo para comprobar que el dataset representa adecuadamente todos los tiempos y no hay desbalance en los datos. ","metadata":{}},{"cell_type":"code","source":"df_final_copy = df_final.copy()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:51:06.375059Z","iopub.execute_input":"2022-05-21T17:51:06.375347Z","iopub.status.idle":"2022-05-21T17:51:06.390340Z","shell.execute_reply.started":"2022-05-21T17:51:06.375317Z","shell.execute_reply":"2022-05-21T17:51:06.389359Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 3, figsize=(12,8))\nsns.barplot(x=df_final_copy.Year.value_counts().index, \n            y=df_final_copy.Year.value_counts().values, \n            palette=cust_color, ax=ax[0],\n           edgecolor='black', linewidth=1.5, saturation=1.5)\nax[0].yaxis.set_major_locator(MaxNLocator(nbins=20))\nax[0].tick_params(axis='x', which='major', labelsize=10, rotation=90)\nax[0].set_ylabel('Count', weight='semibold', fontname = 'monospace', rotation=90)\nax[0].set_xlabel('Year Distribution', weight='semibold', fontname = 'monospace')\n\nax[1].pie(df_final_copy.Month.value_counts(), \n          labels = df_final_copy.Month.value_counts().index, \n          colors = cust_color, autopct='%1.1f%%',\n        explode=[0.03 for i in df_final_copy.Month.value_counts().index])\nax[1].set_xlabel('Month Distribution', weight='semibold', fontname = 'monospace')\n\nax[2].pie(df_final_copy.Day.value_counts(), \n          labels = df_final_copy.Day.value_counts().index, \n          colors = cust_color, autopct='%1.1f%%',\n        explode=[0.03 for i in df_final_copy.Day.value_counts().index])\nax[2].set_xlabel('Day Distribution', weight='semibold', fontname = 'monospace')\n\n\nplt.suptitle('Time Distribution', fontname = 'monospace', weight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:54:20.310356Z","iopub.execute_input":"2022-05-21T17:54:20.310645Z","iopub.status.idle":"2022-05-21T17:54:21.808711Z","shell.execute_reply.started":"2022-05-21T17:54:20.310617Z","shell.execute_reply":"2022-05-21T17:54:21.807959Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Analisis bi-variable\n\nVamos a ver algunas relaciones interesantes para tener una idea más específica del dataset. \n\n### 4.2.1 Country vs City:\n\nA continuación podemos ver qué ciudades son representadas mayormente de cada país. Por ejemplo: La ciudad a la que se le ha hecho más estudios de Alemania es `Duisburg`.","metadata":{}},{"cell_type":"code","source":"fig = px.sunburst(data_frame=df_country,\n                  path=['CountryName', 'City'],\n                  color='City',\n                  color_discrete_sequence=cust_color[::-4],\n                  title='12 top Country vs City '\n                 )\n\nfig.update_traces(textinfo='label')\nfig.update_layout(margin=dict(t=40, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:53:00.482596Z","iopub.execute_input":"2022-05-21T17:53:00.482854Z","iopub.status.idle":"2022-05-21T17:53:01.983698Z","shell.execute_reply.started":"2022-05-21T17:53:00.482826Z","shell.execute_reply":"2022-05-21T17:53:01.982700Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.2 ¿Qué sector es el que contribuye más a la contaminación según el Country?\n\nComo podemos ver `Energy sector` contribuye en primer lugar a UK, después de Alemania e Italia. En cambio la `Industria minera`contribuye más a Italia que Alemania.","metadata":{}},{"cell_type":"code","source":"fig = px.sunburst(data_frame=df_final_copy,\n                  path=['EprtrSectorName', 'CountryName'],\n                  color='CountryName',\n                  color_discrete_sequence=cust_color[::-4],\n                  title='Sector Name vs Country '\n                 )\n\nfig.update_traces(textinfo='label')\nfig.update_layout(margin=dict(t=40, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:09:37.960362Z","iopub.execute_input":"2022-05-21T18:09:37.960660Z","iopub.status.idle":"2022-05-21T18:09:39.158029Z","shell.execute_reply.started":"2022-05-21T18:09:37.960628Z","shell.execute_reply":"2022-05-21T18:09:39.157177Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.3 ¿Dónde hay más días de viento según Country?\n\nEn `UK` hay 11 días de viento mientras que en Alemania y Francia hay 2 y 1 respectivamente. ","metadata":{}},{"cell_type":"code","source":"fig = px.sunburst(data_frame=df_final_copy,\n                  path=['CountryName', 'Day of fogs'],\n                  color='Day of fogs',\n                  color_discrete_sequence=cust_color[::-4],\n                  title='12 top Country vs City '\n                 )\n\nfig.update_traces(textinfo='label')\nfig.update_layout(margin=dict(t=40, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:13:29.603463Z","iopub.execute_input":"2022-05-21T18:13:29.603898Z","iopub.status.idle":"2022-05-21T18:13:30.855582Z","shell.execute_reply.started":"2022-05-21T18:13:29.603867Z","shell.execute_reply":"2022-05-21T18:13:30.854722Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"df_final_copy_cont = df_final_copy.select_dtypes(include=['float64','int64'])","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:30:30.583195Z","iopub.execute_input":"2022-05-21T18:30:30.583512Z","iopub.status.idle":"2022-05-21T18:30:30.592522Z","shell.execute_reply.started":"2022-05-21T18:30:30.583476Z","shell.execute_reply":"2022-05-21T18:30:30.591539Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Análisis del target\n\nEn el análisis univariable ya hemos visto la distribución del target. Ahora veremos cómo se relacionada con otras variables.\n\nVemos que Nitrogen oxides y Carbon dioxide están más presentes en `Alemania` mientras que Methane está más presente en `UK`.","metadata":{}},{"cell_type":"code","source":"fig = px.sunburst(data_frame=df_final_copy,\n                  path=['Pollutant', 'CountryName'],\n                  color='CountryName',\n                  color_discrete_sequence=cust_color[::-4],\n                  title='Pollutant vs Country '\n                 )\n\nfig.update_traces(textinfo='label')\nfig.update_layout(margin=dict(t=40, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:12:01.593062Z","iopub.execute_input":"2022-05-21T18:12:01.593379Z","iopub.status.idle":"2022-05-21T18:12:02.761686Z","shell.execute_reply.started":"2022-05-21T18:12:01.593341Z","shell.execute_reply":"2022-05-21T18:12:02.760833Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"A continuación, analizaremos la relación entre Pollutant y Year. Gracias a ello podemos ver, que los años finales 2018-2019-2020 hay menos contaminación en la atmosfera por estos gases que en los primeros años. Esto es debido a las políticas empleadas para su disminución.","metadata":{}},{"cell_type":"code","source":"fig = px.sunburst(data_frame=df_final_copy,\n                  path=['Pollutant', 'Year'],\n                  color='Year',\n                  color_discrete_sequence=cust_color[::-4],\n                  title='Pollutant vs Year'\n                 )\n\nfig.update_traces(textinfo='label')\nfig.update_layout(margin=dict(t=40, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:12:37.087205Z","iopub.execute_input":"2022-05-21T18:12:37.087833Z","iopub.status.idle":"2022-05-21T18:12:38.273610Z","shell.execute_reply.started":"2022-05-21T18:12:37.087782Z","shell.execute_reply":"2022-05-21T18:12:38.272620Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"Seguidamente, veremos cuál es la actividad que genera más polución a la atmosfera. Como podemos ver las `instalaciones de carbono` son las que más contribuyen a la emisión de estos gases. ","metadata":{}},{"cell_type":"code","source":"fig = px.sunburst(data_frame=df_final_copy,\n                  path=['Pollutant', 'EPRTRAnnexIMainActivityLabel'],\n                  color='EPRTRAnnexIMainActivityLabel',\n                  color_discrete_sequence=cust_color[::-4],\n                  title='¿Qué actividad provoca más polución? '\n                 )\n\nfig.update_traces(textinfo='label')\nfig.update_layout(margin=dict(t=40, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:12:47.612122Z","iopub.execute_input":"2022-05-21T18:12:47.612860Z","iopub.status.idle":"2022-05-21T18:12:48.842467Z","shell.execute_reply.started":"2022-05-21T18:12:47.612812Z","shell.execute_reply":"2022-05-21T18:12:48.841784Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"# 5. Correcciones del test\n\nEl test es el dataset en bruto. No le aplicaremos casi ninguna transformación pero sí quiero ordenar las columnas y eliminar esas que no son significativas según nuestro criterio.","metadata":{}},{"cell_type":"code","source":"test = test[['test_index','CITY ID', 'CONTINENT', 'City', 'DAY', 'DAY WITH FOGS',\n       'EPRTRAnnexIMainActivityLabel', 'FacilityInspireID', 'MONTH',\n       'REPORTER NAME', 'avg_temp', 'avg_wind_speed', 'countryName',\n       'eprtrSectorName', 'facilityName', 'max_temp', 'max_wind_speed',\n       'min_temp', 'min_wind_speed', 'reportingYear',\n       'targetRelease']]","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:49:15.156798Z","iopub.execute_input":"2022-05-21T18:49:15.157088Z","iopub.status.idle":"2022-05-21T18:49:15.168082Z","shell.execute_reply.started":"2022-05-21T18:49:15.157054Z","shell.execute_reply":"2022-05-21T18:49:15.167073Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"test.columns =  ['test_index','City Id', 'Continent', 'City', 'Day', 'Day of fogs',\n       'EPRTRAnnexIMainActivityLabel', 'FacilityInspireID', 'Month',\n       'Reporter name', 'Avg_temp', 'Avg_wind_speed', 'CountryName',\n       'EprtrSectorName', 'FacilityName', 'Max_temp', 'Max_wind_speed',\n       'Min_temp', 'Min_wind_speed', 'Year',\n       'TargetRelease']","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:50:33.877606Z","iopub.execute_input":"2022-05-21T18:50:33.877931Z","iopub.status.idle":"2022-05-21T18:50:33.883656Z","shell.execute_reply.started":"2022-05-21T18:50:33.877898Z","shell.execute_reply":"2022-05-21T18:50:33.883036Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"test = test.drop(['City Id','Continent','FacilityInspireID','Reporter name','FacilityName','TargetRelease'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:52:08.557784Z","iopub.execute_input":"2022-05-21T18:52:08.558659Z","iopub.status.idle":"2022-05-21T18:52:08.567095Z","shell.execute_reply.started":"2022-05-21T18:52:08.558617Z","shell.execute_reply":"2022-05-21T18:52:08.566189Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"markdown","source":"# 6. Algoritmo\n\nAhora vamos a contruir nuestro algoritmo. Primero vamos a transformar las columnas tipo `object` en formato numérico no ordinal. Para ello usamos la librería LabelEnconder. Como vemos a continuación, antes que nada, comprobamos si hay valores nulos y sus características generales.","metadata":{}},{"cell_type":"code","source":"df_final_copy.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:18:40.140024Z","iopub.execute_input":"2022-05-21T18:18:40.140306Z","iopub.status.idle":"2022-05-21T18:18:40.193528Z","shell.execute_reply.started":"2022-05-21T18:18:40.140277Z","shell.execute_reply":"2022-05-21T18:18:40.192479Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"markdown","source":"Vamos a separar el `train` en `X` e `y`, y vamos a dividir según datos tipo `object`  o no. Seguidamente le aplicaremos a los datos `object` el LabelEncoder.","metadata":{}},{"cell_type":"code","source":"y = df_final_copy['Pollutant']\nX = df_final_copy.drop(['Pollutant'], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_cat = X.select_dtypes(include='object')\nX_cont = X.select_dtypes(include=['int64','float64'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:22:13.912491Z","iopub.execute_input":"2022-05-21T18:22:13.912779Z","iopub.status.idle":"2022-05-21T18:22:13.916930Z","shell.execute_reply.started":"2022-05-21T18:22:13.912750Z","shell.execute_reply":"2022-05-21T18:22:13.916035Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"X_cat = X_cat.apply(le.fit_transform)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:26:44.204179Z","iopub.execute_input":"2022-05-21T18:26:44.204488Z","iopub.status.idle":"2022-05-21T18:26:44.332487Z","shell.execute_reply.started":"2022-05-21T18:26:44.204455Z","shell.execute_reply":"2022-05-21T18:26:44.331605Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":"Ahora uniremos los datos tipo `object` y los otros en un nuevo dataframe numérico.","metadata":{}},{"cell_type":"code","source":"X_final = pd.concat([X_cont, X_cat],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:27:09.661183Z","iopub.execute_input":"2022-05-21T18:27:09.661475Z","iopub.status.idle":"2022-05-21T18:27:09.671988Z","shell.execute_reply.started":"2022-05-21T18:27:09.661441Z","shell.execute_reply":"2022-05-21T18:27:09.671208Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"Ahora, vamos a hacer lo mismo para el `test`.","metadata":{}},{"cell_type":"code","source":"test_cat = test.select_dtypes(include='object')\ntest_cont = test.select_dtypes(exclude='object')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:56:10.688695Z","iopub.execute_input":"2022-05-21T18:56:10.689005Z","iopub.status.idle":"2022-05-21T18:56:10.698469Z","shell.execute_reply.started":"2022-05-21T18:56:10.688960Z","shell.execute_reply":"2022-05-21T18:56:10.697589Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"test_cat_enc=test_cat.apply(le.fit_transform)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:56:26.927949Z","iopub.execute_input":"2022-05-21T18:56:26.928800Z","iopub.status.idle":"2022-05-21T18:56:26.975891Z","shell.execute_reply.started":"2022-05-21T18:56:26.928760Z","shell.execute_reply":"2022-05-21T18:56:26.975050Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"test_final = pd.concat([test_cont,test_cat_enc],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:58:16.496817Z","iopub.execute_input":"2022-05-21T18:58:16.497146Z","iopub.status.idle":"2022-05-21T18:58:16.504004Z","shell.execute_reply.started":"2022-05-21T18:58:16.497117Z","shell.execute_reply":"2022-05-21T18:58:16.503066Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"markdown","source":"## 5.1 Selección de características\n\nQuiero realizar este apartado para ver que características, según el modelo mutual information, son más relevantes. Si nos fijamos son dice que las características:\n'Year', 'City','EPRTRAnnexIMainActivityLabel' y 'CountryName' son las más relevantes.","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot\n\nx_train_split, x_test_split, y_train_split, y_test_split = train_test_split(X_final, y, test_size=0.33, random_state=2022)\n\n# feature selection\ndef select_features_mutual(X_train, y_train, X_test):\n    # configure to select all features\n    fs = SelectKBest(score_func=mutual_info_classif, k='all')\n    # learn relationship from training data\n    fs.fit(X_train, y_train)\n    # transform train input data\n    X_train_fs = fs.transform(X_train)\n    # transform test input data\n    X_test_fs = fs.transform(X_test)\n    return X_train_fs, X_test_fs, fs\n\n# feature selection\nX_train_mutual, X_test_mutal, mutual = select_features_mutual(x_train_split, y_train_split, x_test_split)\n\n\n# what are scores for the features\nfor i in range(len(mutual.scores_)):\n    print('Feature %d: %f' % (i, mutual.scores_[i]))\n    # plot the scores\npyplot.title('Mutual info classification feature selection\\n', fontdict=None, loc='center')\npyplot.bar([i for i in range(len(mutual.scores_))], mutual.scores_)\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:06:17.350004Z","iopub.execute_input":"2022-05-21T19:06:17.350315Z","iopub.status.idle":"2022-05-21T19:06:22.532016Z","shell.execute_reply.started":"2022-05-21T19:06:17.350284Z","shell.execute_reply":"2022-05-21T19:06:22.531003Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Creación del modelo:\n\nHemos escogido un modelo donde las característica que tienen poco peso pasen a ser más significativas para no perder información. Esto lo hacemos gracias al algoritmo de Deep Learning Gated Residual Network y Variable Selection. \n- `Paso 1`: Determinar las variables del dataset para entrenarlo","metadata":{}},{"cell_type":"code","source":"# split dataframes for later modeling\nX = X_final.copy()\ny = y.copy()\n\nX_test_id = test_final.copy() # este tiene el id\nX_test = X_test_id.drop(['test_index'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:11:15.536510Z","iopub.execute_input":"2022-05-21T19:11:15.536811Z","iopub.status.idle":"2022-05-21T19:11:15.549721Z","shell.execute_reply.started":"2022-05-21T19:11:15.536782Z","shell.execute_reply":"2022-05-21T19:11:15.548703Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 2`: Comprobar el tamaño del dataset:","metadata":{}},{"cell_type":"code","source":"print(X.shape, y.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:11:20.679190Z","iopub.execute_input":"2022-05-21T19:11:20.679483Z","iopub.status.idle":"2022-05-21T19:11:20.686459Z","shell.execute_reply.started":"2022-05-21T19:11:20.679448Z","shell.execute_reply":"2022-05-21T19:11:20.685448Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 3`: Aplicar encoding al target con keras.io","metadata":{}},{"cell_type":"code","source":"target = keras.utils.to_categorical(le.fit_transform(y))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:11:31.672782Z","iopub.execute_input":"2022-05-21T19:11:31.673776Z","iopub.status.idle":"2022-05-21T19:11:31.707336Z","shell.execute_reply.started":"2022-05-21T19:11:31.673733Z","shell.execute_reply":"2022-05-21T19:11:31.706614Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 4`: Comprobar una vez más el tamaño del dataset","metadata":{}},{"cell_type":"code","source":"gc.collect()\nprint(X.shape, y.shape, target.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:11:51.426133Z","iopub.execute_input":"2022-05-21T19:11:51.426442Z","iopub.status.idle":"2022-05-21T19:11:51.855888Z","shell.execute_reply.started":"2022-05-21T19:11:51.426409Z","shell.execute_reply":"2022-05-21T19:11:51.854822Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 5`: Definir las funciones de ayuda de nuestro dataset:\n    - set_seed: para determinar el seed\n    - plot_eval_results: para ilustrar los gráficos sobre las funciones de pérdida según el cv escogido.\n    - plot_cv: para visualizar las métricas de nuestro dataset. Recordamos que la métrica que nos importa es `f1-score`.","metadata":{}},{"cell_type":"code","source":"# define helper functions\ndef set_seed(seed):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    print(f\"Seed set to: {seed}\")\n\ndef plot_eval_results(scores, n_splits):\n    cols = 10\n    rows = int(np.ceil(n_splits/cols))\n    \n    fig, ax = plt.subplots(rows, cols, tight_layout=True, figsize=(20,2.5))\n    ax = ax.flatten()\n\n    for fold in range(len(scores)):\n        df_eval = pd.DataFrame({'train_loss': scores[fold]['loss'], 'valid_loss': scores[fold]['val_loss']})\n\n        sns.lineplot(\n            x=df_eval.index,\n            y=df_eval['train_loss'],\n            label='train_loss',\n            ax=ax[fold]\n        )\n\n        sns.lineplot(\n            x=df_eval.index,\n            y=df_eval['valid_loss'],\n            label='valid_loss',\n            ax=ax[fold]\n        )\n\n        ax[fold].set_ylabel('')\n\n    sns.despine()\n\ndef plot_cm(cm):\n    metrics = {\n        'accuracy': cm / cm.sum(),\n        'recall' : cm / cm.sum(axis=1),\n        'precision': cm / cm.sum(axis=0)\n    }\n    \n    fig, ax = plt.subplots(1,3, tight_layout=True, figsize=(15,5))\n    ax = ax.flatten()\n\n    mask = (np.eye(cm.shape[0]) == 0) * 1\n\n    for idx, (name, matrix) in enumerate(metrics.items()):\n\n        ax[idx].set_title(name)\n\n        sns.heatmap(\n            data=matrix,\n            cmap=sns.dark_palette(\"#69d\", reverse=True, as_cmap=True),\n            cbar=False,\n            mask=mask,\n            lw=0.25,\n            annot=True,\n            fmt='.2f',\n            ax=ax[idx]\n        )\n    sns.despine()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:12:12.152190Z","iopub.execute_input":"2022-05-21T19:12:12.152461Z","iopub.status.idle":"2022-05-21T19:12:12.167985Z","shell.execute_reply.started":"2022-05-21T19:12:12.152433Z","shell.execute_reply":"2022-05-21T19:12:12.166994Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 6`: Vamos a difinir dos callbacks: ReduceLROnPlateau y EarlyStopping donde le hemos aplicado el loss de `f1-score`.","metadata":{}},{"cell_type":"code","source":"# define callbacks\nlr = keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\", \n    factor=0.5, \n    patience=5, \n    verbose=True\n)\n\nes = keras.callbacks.EarlyStopping(\n    monitor=\"val_get_f1\", \n    patience=10, \n    verbose=True, \n    mode=\"max\", \n    restore_best_weights=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:12:23.281004Z","iopub.execute_input":"2022-05-21T19:12:23.281502Z","iopub.status.idle":"2022-05-21T19:12:23.286591Z","shell.execute_reply.started":"2022-05-21T19:12:23.281448Z","shell.execute_reply":"2022-05-21T19:12:23.285862Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 7`: contruir nuestro modelo integro teniendo en cuenta la métrica requerida.","metadata":{}},{"cell_type":"code","source":"class GatedLinearUnit(layers.Layer):\n    def __init__(self, units):\n        super(GatedLinearUnit, self).__init__()\n        self.linear = layers.Dense(units)\n        self.sigmoid = layers.Dense(units, activation=\"sigmoid\")\n\n    def call(self, inputs):\n        return self.linear(inputs) * self.sigmoid(inputs)\n\nclass GatedResidualNetwork(layers.Layer):\n    def __init__(self, units, dropout_rate):\n        super(GatedResidualNetwork, self).__init__()\n        self.units = units\n        self.elu_dense = layers.Dense(units, activation=\"elu\")\n        self.linear_dense = layers.Dense(units)\n        self.dropout = layers.Dropout(dropout_rate)\n        self.gated_linear_unit = GatedLinearUnit(units)\n        self.layer_norm = layers.LayerNormalization()\n        self.project = layers.Dense(units)\n\n    def call(self, inputs):\n        x = self.elu_dense(inputs)\n        x = self.linear_dense(x)\n        x = self.dropout(x)\n        if inputs.shape[-1] != self.units:\n            inputs = self.project(inputs)\n        x = inputs + self.gated_linear_unit(x)\n        x = self.layer_norm(x)\n        return x\n\nclass VariableSelection(layers.Layer):\n    def __init__(self, num_features, units, dropout_rate):\n        super(VariableSelection, self).__init__()\n        self.grns = list()\n        for idx in range(num_features):\n            grn = GatedResidualNetwork(units, dropout_rate)\n            self.grns.append(grn)\n        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n        self.softmax = layers.Dense(units=num_features, activation=\"softmax\")\n\n    def call(self, inputs):\n        v = layers.concatenate(inputs)\n        v = self.grn_concat(v)\n        v = tf.expand_dims(self.softmax(v), axis=-1)\n\n        x = []\n        for idx, input in enumerate(inputs):\n            x.append(self.grns[idx](input))\n        x = tf.stack(x, axis=1)\n\n        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:12:33.288779Z","iopub.execute_input":"2022-05-21T19:12:33.289090Z","iopub.status.idle":"2022-05-21T19:12:33.305884Z","shell.execute_reply.started":"2022-05-21T19:12:33.289057Z","shell.execute_reply":"2022-05-21T19:12:33.305220Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 8`: Contrucción de los inputs y el encode.","metadata":{}},{"cell_type":"code","source":"def create_model_inputs():\n    inputs = {}\n    for feature_name in X.columns:\n        inputs[feature_name] = layers.Input(\n            name=feature_name, shape=(), dtype=tf.float32\n        )\n    return inputs\n\ndef encode_inputs(inputs, encoding_size):\n    encoded_features = []\n    for col in range(inputs.shape[1]):\n        encoded_feature = tf.expand_dims(inputs[:, col], -1)\n        encoded_feature = layers.Dense(units=encoding_size)(encoded_feature)\n        encoded_features.append(encoded_feature)\n    return encoded_features\n\ndef create_model(encoding_size, dropout_rate=0.15):\n    inputs = layers.Input(len(X.columns))\n    feature_list = encode_inputs(inputs, encoding_size)\n    num_features = len(feature_list)\n\n    features = VariableSelection(num_features, encoding_size, dropout_rate)(\n        feature_list\n    )\n\n    outputs = layers.Dense(units=target.shape[-1], activation=\"softmax\")(features)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:12:44.063785Z","iopub.execute_input":"2022-05-21T19:12:44.064599Z","iopub.status.idle":"2022-05-21T19:12:44.073928Z","shell.execute_reply.started":"2022-05-21T19:12:44.064558Z","shell.execute_reply":"2022-05-21T19:12:44.073134Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 9`: Remarcar las excepciones del modelo.","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    tf_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print(\"Running on TPU:\", tpu.master())\nexcept:\n    tf_strategy = tf.distribute.get_strategy()\n    print(f\"Running on {tf_strategy.num_replicas_in_sync} replicas\")\n    print(\"Number of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:12:53.679994Z","iopub.execute_input":"2022-05-21T19:12:53.680289Z","iopub.status.idle":"2022-05-21T19:12:53.702712Z","shell.execute_reply.started":"2022-05-21T19:12:53.680259Z","shell.execute_reply":"2022-05-21T19:12:53.702012Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 10`: crear la función de la métrica que el problema nos demanda.","metadata":{}},{"cell_type":"code","source":"def get_f1(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:13:06.057669Z","iopub.execute_input":"2022-05-21T19:13:06.057995Z","iopub.status.idle":"2022-05-21T19:13:06.064708Z","shell.execute_reply.started":"2022-05-21T19:13:06.057941Z","shell.execute_reply":"2022-05-21T19:13:06.064038Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"markdown","source":"- `Paso 11`: importar todo el modelo para entrenarlo","metadata":{}},{"cell_type":"code","source":"seed = 2022\nset_seed(seed)\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n\npredictions = []\noof_preds = {'y_valid': list(), 'y_hat': list()}\nscores_nn = {fold:None for fold in range(cv.n_splits)}\n\nfor fold, (idx_train, idx_valid) in enumerate(cv.split(X,y)):\n    X_train, y_train = X.iloc[idx_train], target[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], target[idx_valid]\n    \n    scl = RobustScaler()\n    X_train = scl.fit_transform(X_train)\n    X_valid = scl.transform(X_valid)\n    \n    with tf_strategy.scope():\n        model = create_model(encoding_size=128)\n\n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n            loss=keras.losses.CategoricalCrossentropy(),\n            metrics=[get_f1]\n        )\n        \n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_valid, y_valid),\n        epochs=90,\n        batch_size=4096,\n        shuffle=True,\n        verbose=False,\n        callbacks=[lr,es]\n    )\n    \n    scores_nn[fold] = history.history\n    \n    oof_preds['y_valid'].extend(y.iloc[idx_valid])\n    oof_preds['y_hat'].extend(model.predict(X_valid, batch_size=4096))\n    \n    prediction = model.predict(scl.transform(X_test), batch_size=4096) \n    predictions.append(prediction)\n    \n    #del model, prediction\n    gc.collect()\n    K.clear_session()\n    \n    print('_'*65)\n    print(f\"Fold {fold+1} || Min Val Loss: {np.min(scores_nn[fold]['val_loss'])}\")\n    print('_'*65)\n    \nprint('_'*65)\noverall_score = [np.min(scores_nn[fold]['val_loss']) for fold in range(cv.n_splits)]\nprint(f\"Overall Mean Validation Loss: {np.mean(overall_score)}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-21T19:13:17.218916Z","iopub.execute_input":"2022-05-21T19:13:17.219657Z","iopub.status.idle":"2022-05-21T19:43:42.549740Z","shell.execute_reply.started":"2022-05-21T19:13:17.219619Z","shell.execute_reply":"2022-05-21T19:43:42.548744Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Evaluación del modelo:","metadata":{}},{"cell_type":"code","source":"#plot_eval_results(scores_nn, cv.n_splits)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T20:59:30.342227Z","iopub.execute_input":"2022-05-21T20:59:30.343165Z","iopub.status.idle":"2022-05-21T20:59:32.918860Z","shell.execute_reply.started":"2022-05-21T20:59:30.343100Z","shell.execute_reply":"2022-05-21T20:59:32.918184Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"markdown","source":"## 5.4 Observación de las métricas","metadata":{}},{"cell_type":"code","source":"# prepare oof_predictions\noof_y_true = np.array(oof_preds['y_valid'])\noof_y_hat = le.inverse_transform(np.argmax(oof_preds['y_hat'], axis=1))\n\n# create confusion matrix, calculate accuracy, recall & precision\ncm = pd.DataFrame(data=confusion_matrix(oof_y_true, oof_y_hat, labels=le.classes_), index=le.classes_, columns=le.classes_)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:00:53.160534Z","iopub.execute_input":"2022-05-21T21:00:53.160840Z","iopub.status.idle":"2022-05-21T21:00:53.394780Z","shell.execute_reply.started":"2022-05-21T21:00:53.160810Z","shell.execute_reply":"2022-05-21T21:00:53.394001Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(oof_y_true, oof_y_hat)\nix = np.arange(cm.shape[0])\ncm[ix, ix] = 0\ncol_names = [f'Polucion={cls}' for cls in le.classes_]\ncm = pd.DataFrame(cm, columns=col_names, index=col_names)\nsns.heatmap(cm, cmap='Blues', annot=True, fmt='d').set(title=f'{cm.sum().sum()} misses\\n ');","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:01:22.730470Z","iopub.execute_input":"2022-05-21T21:01:22.730753Z","iopub.status.idle":"2022-05-21T21:01:26.122204Z","shell.execute_reply.started":"2022-05-21T21:01:22.730725Z","shell.execute_reply":"2022-05-21T21:01:26.121224Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(oof_y_true, oof_y_hat)\nix = np.arange(cm.shape[0])\ncol_names = [f'Polución={cls}' for cls in le.classes_]\ncm = pd.DataFrame(cm, columns=col_names, index=col_names)\nsns.heatmap(cm, cmap='Blues', annot=True, fmt='d').set(title=f'Confusion matrix\\n');","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:01:34.427569Z","iopub.execute_input":"2022-05-21T21:01:34.427870Z","iopub.status.idle":"2022-05-21T21:01:37.820195Z","shell.execute_reply.started":"2022-05-21T21:01:34.427835Z","shell.execute_reply":"2022-05-21T21:01:37.819569Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"markdown","source":"Como podemos observar, hay muchos datos erróneamente clasificados. Esto es un problema que se debería solventar. Ahora vamos a ver el reporte:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:02:27.388494Z","iopub.execute_input":"2022-05-21T21:02:27.388784Z","iopub.status.idle":"2022-05-21T21:02:27.393801Z","shell.execute_reply.started":"2022-05-21T21:02:27.388755Z","shell.execute_reply":"2022-05-21T21:02:27.392876Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"print(classification_report(oof_y_true, oof_y_hat))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:02:29.080487Z","iopub.execute_input":"2022-05-21T21:02:29.080803Z","iopub.status.idle":"2022-05-21T21:02:31.322696Z","shell.execute_reply.started":"2022-05-21T21:02:29.080772Z","shell.execute_reply":"2022-05-21T21:02:31.321761Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"markdown","source":"Vemos que `f1-score (macro)` es del 0.61. Es bastante bajo. Se debería replantear algunos criterios para intentar mejorarlo.","metadata":{}},{"cell_type":"markdown","source":"## 5.4 Resultados finales","metadata":{}},{"cell_type":"code","source":"#create final prediction, inverse labels to original classes\nfinal_predictions = le.inverse_transform(np.argmax(sum(predictions), axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:03:34.863307Z","iopub.execute_input":"2022-05-21T21:03:34.863591Z","iopub.status.idle":"2022-05-21T21:03:34.871394Z","shell.execute_reply.started":"2022-05-21T21:03:34.863560Z","shell.execute_reply":"2022-05-21T21:03:34.870598Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"#submission\nsubmission = X_test_id.drop(['Day', 'Day of fogs', 'Month', 'Avg_temp',\n       'Avg_wind_speed', 'Max_temp', 'Max_wind_speed', 'Min_temp',\n       'Min_wind_speed', 'Year', 'City', 'EPRTRAnnexIMainActivityLabel',\n       'CountryName', 'EprtrSectorName'], axis=1)\nsubmission['Prediction'] = final_predictions\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:08:05.678734Z","iopub.execute_input":"2022-05-21T21:08:05.679046Z","iopub.status.idle":"2022-05-21T21:08:05.693252Z","shell.execute_reply.started":"2022-05-21T21:08:05.679008Z","shell.execute_reply":"2022-05-21T21:08:05.692356Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('predictions.csv', index=False)\nsubmission.to_json('predictions.json')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:09:03.639915Z","iopub.execute_input":"2022-05-21T21:09:03.640597Z","iopub.status.idle":"2022-05-21T21:09:03.737885Z","shell.execute_reply.started":"2022-05-21T21:09:03.640564Z","shell.execute_reply":"2022-05-21T21:09:03.737179Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"markdown","source":"Como se puede ver, la mayoría de predicciones de los datos `test` han sido NOX.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(18, 10))\nfig.suptitle('\\nNúmero de predicciones para las diferentes categorías de Polución\\n\\n', size=25)\nsns.countplot(final_predictions,palette = \"Blues\")\nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T21:10:20.336103Z","iopub.execute_input":"2022-05-21T21:10:20.336387Z","iopub.status.idle":"2022-05-21T21:10:21.482936Z","shell.execute_reply.started":"2022-05-21T21:10:20.336359Z","shell.execute_reply":"2022-05-21T21:10:21.482152Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}